# MViTv2: Improved Multiscale Vision Transformers for Classification and Detection

![image](https://github.com/user-attachments/assets/f60f79f0-6db5-4e53-8698-a54b8e6a0e6c)

###1.decomposed relative position embedding
ViT divide into non-overlapping patches as tokens, introduces absolute position of 
patches (in a sequence), rather than their relative spatial relationships. (BTW,
CNN uses pooling and kernel inherently provide translation invariance)

