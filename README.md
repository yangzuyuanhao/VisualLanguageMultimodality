
# VLM-Action
Brief tutorial vision-launguage large model related works: modeling, finetune, parallel training, quantize, deployment, etc.


## 1. Modeling
(TO BE UPDATED)

## 2. Finetune
Cover common large model finetune strategies prefix, prompt, p-tuning, p-tuning v2, lora. 

[2.1 Introduce to finetune methods doc](https://github.com/yzy-jumphigh/vlm-action/blob/main/Tuning/README.md) 

[2.2 lora with llama2 pytorch code](https://github.com/yzy-jumphigh/vlm-action/blob/main/Tuning/llama2_lora.py) 

[2.3 prefix with llama2 pytorch code](https://github.com/yzy-jumphigh/vlm-action/blob/main/Tuning/llama2_prefix.py) 

[2.4 ptune-v2 with llama2 pytorch code](https://github.com/yzy-jumphigh/vlm-action/blob/main/Tuning/llama2_ptune_v2.py) 

[2.5 prefix with llama2 pytorch code](https://github.com/yzy-jumphigh/vlm-action/blob/main/Tuning/llama2_prompt.py) 

## 3. Parallel Training

### 3.1 Tensor parallel


### 3.2 Zeros
Talk about how to utilize zero on large model training, and, how to apply deepspeed within your train pipeline. 

[3.1 Optimizer analyze doc](https://github.com/yzy-jumphigh/vlm-action/blob/main/Zero/doc/Optimizer%20States%20Overview.md) 

[3.2 Deepspeed overview doc](https://github.com/yzy-jumphigh/vlm-action/blob/main/Zero/doc/Deepspeed%20Overview.md) 

[3.3 Deepspeed stage 2 doc](https://github.com/yzy-jumphigh/vlm-action/blob/main/Zero/doc/DeepSpeed%20Stage2.md) 

[3.4 Deepspeed stage 3 doc](https://github.com/yzy-jumphigh/vlm-action/blob/main/Zero/doc/DeepSpeed%20Stage3.md) 








