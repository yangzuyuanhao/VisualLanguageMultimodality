
# VLM-Action
Brief tutorial vision-launguage large model related works: modeling, finetune, parallel training, quantize, deployment, etc.


## 1. Modeling
(TO BE UPDATED)

## 2. Finetune
Cover common large model finetune strategies prefix, prompt, p-tuning, p-tuning v2, lora. 

[2.1 Introduce to finetune methods doc](https://github.com/yzy-jumphigh/vlm-action/blob/main/finetune/overview.md) 

[2.2 lora with llama2 pytorch code](https://github.com/yzy-jumphigh/vlm-action/blob/main/finetune/llama2_lora.py) 

[2.3 prefix with llama2 pytorch code](https://github.com/yzy-jumphigh/vlm-action/blob/main/finetune/llama2_prefix.py) 

[2.4 ptune-v2 with llama2 pytorch code](https://github.com/yzy-jumphigh/vlm-action/blob/main/finetune/llama2_ptune_v2.py) 

[2.5 prefix with llama2 pytorch code](https://github.com/yzy-jumphigh/vlm-action/blob/main/finetune/llama2_prompt.py) 

## 3. Parallel Training

### 3.1 Tensor parallel


### 3.2 Distrubited Training
Talk about how to utilize zero on large model training, and, how to apply deepspeed within your train pipeline.    
[3.2.1 deepspeed overview doc](https://github.com/yzy-jumphigh/vlm-action/blob/training/zero_overview.md)   










